<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Reading the Algorithm: Exploring Critical AI Literacy Through Distant Reading</title>
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <!-- Header -->
    <header>
        <div class="banner-container">
            <img src="../banner.jpg" alt="Portfolio Banner" class="banner">
            <div class="banner-text">Reading the Algorithm: Exploring Critical AI Literacy Through Distant Reading</div>
        </div>
        <nav>
            <ul class="menu">
                <li><a href="../index.html">Home</a></li>
                <li><a href="#description">Description</a></li>
                <li><a href="#tools">Tools</a></li>
            </ul>
        </nav>
    </header>

    <!-- Main Content -->
    <main>
        <section id="description">
            <h2>Project Description</h2>
            <img src="project1.jpg" alt="Project 1 Image" class="project-detail-image">
            <p>This project connects distant reading techniques with a critical examination of "critical AI literacy" discourse, exploring how search engines and Wikipedia shape perceptions of literacy in the age of AI. Through two distinct datasets—Google Programmable Search Engine (PSE) results and Wikipedia pages about various literacies—the project demonstrates how computational methods can uncover patterns in cultural and educational discourse.</p>

                <p>The first dataset focused on the top 100 Google search results for "critical AI literacy" and "AI literacy," filtered across both the .edu domain and the broader web. Metadata such as page titles, snippets, and URLs were analyzed to identify word frequency patterns, revealing trends like the prominence of "writing" within .edu results for "critical AI literacy." Domain analysis further highlighted how search algorithms emphasize particular sources, offering a window into how these terms are framed within academic and general contexts. While the limited dataset imposed by Google's search result cap presented challenges, it also aligned with Safiya Noble’s critique of search engine ranking systems in <em>Algorithms of Oppression</em>.</p>
                
                    <p>To complement this smaller dataset, the second dataset analyzed 37 Wikipedia pages on different literacies, from "digital literacy" to "AI literacy." By scraping page content and metadata via the MediaWiki API, the project examined word frequencies and performed sentiment analysis using the TextBlob library. The sentiment heatmap indicated that the "AI literacy" page was slightly negative and among the most subjective in tone, reflecting skepticism and the newness of the topic. This analysis underscores how Wikipedia entries, like search engines, frame literacy-related discourse within specific cultural and technological contexts.</p>
                
                        <p>The workflow for both datasets relied heavily on ChatGPT and Google Colab, streamlining processes such as code generation, data analysis, and visualization. ChatGPT’s capacity to quickly iterate scripts enabled broader experimentation, encouraging a more dynamic exploration of research questions. This iterative process not only saved time but also deepened the researcher’s understanding of Python workflows and computational methods.</p>
                
                            <p>By combining computational analysis with critical perspectives, this project reflects on how algorithms and data structures influence public discourse around critical AI literacy. It also highlights the importance of questioning the subjectivity embedded in classification systems and search engines, pushing for a nuanced understanding of literacy in the digital age.</p>
        </section>

        <section id="tools">
            <h2>Tools & Details</h2>
            <p><strong>Date:</strong> September 2024</p>
            <p><strong>Tools:</strong></p>
            <p>Google Programmable Search Engine (PSE)</p>
<p>MediaWiki API (for Wikipedia data)</p>
<p>Python (for data analysis and visualization)</p>
<p>Libraries: Pandas, Matplotlib, Seaborn, TextBlob</p>
<p>Google Colab (for workflow execution)</p>
<p>ChatGPT (for code generation and refinement)</p>
        </section>
    </main>

    <!-- Footer -->
    <footer>
        <p><a href="../index.html" class="portfolio-link">Back to Portfolio</a></p>
    </footer>
</body>
</html>